version: '3.7'

services:
  llm_app:
    container_name: llm_app
    image: app_image
    env_file:
      - ./.env
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./:/app
      - ./mlruns:/app/mlruns
    ports:
      - "8000:8000"
      - "80:8000"
      - "443:8000"

    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
  
    depends_on:
      - mlflow

  mlflow:
    container_name: mlflow
    image: ghcr.io/mlflow/mlflow:v2.0.1
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlruns
      - ./mlartifacts:/mlartifacts


    command: mlflow server --host 0.0.0.0 --port 5000
